"""
Dashboard EDA para Streamlit - Sistema COVID-19 IA
Autor: Sistema IA COVID-19  
Descripci√≥n: Dashboard interactivo para an√°lisis exploratorio de datos con reportes PDF
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import sys
import os

# Agregar rutas para imports
sys.path.append('src')

try:
    from sistema_multilenguaje.sistema_multilenguaje import t, gestor_multilenguaje
    from analisis_eda.analizador_eda_covid import analizador_eda
    MODULOS_DISPONIBLES = True
except ImportError as e:
    print(f"‚ö†Ô∏è Error importando m√≥dulos: {e}")
    MODULOS_DISPONIBLES = False
    
    # Funciones fallback
    def t(clave): return clave

# Importar generador de reportes PDF
try:
    from reportes_pdf.generador_reportes import generador_reportes
    REPORTES_DISPONIBLES = True
except ImportError:
    print("‚ö†Ô∏è Generador de reportes PDF no disponible")
    REPORTES_DISPONIBLES = False

class DashboardEDA:
    """Dashboard interactivo para an√°lisis exploratorio de datos COVID-19"""
    
    def __init__(self):
        """Inicializa el dashboard EDA"""
        self.dataset_cache = None
        self.reporte_cache = None
        
    @st.cache_data
    def cargar_dataset_covid(_self, tama√±o_muestra: int = 1000) -> pd.DataFrame:
        """
        Carga o genera dataset COVID-19 para an√°lisis
        
        Args:
            tama√±o_muestra (int): Tama√±o del dataset a generar
            
        Returns:
            pd.DataFrame: Dataset de radiograf√≠as COVID-19
        """
        if not MODULOS_DISPONIBLES:
            # Dataset simple de fallback
            np.random.seed(42)
            clases = ['Normal', 'COVID-19', 'Opacidad Pulmonar', 'Neumon√≠a Viral']
            datos = []
            
            for i in range(tama√±o_muestra):
                datos.append({
                    'id_imagen': f'IMG_{i:04d}',
                    'clase_diagnostico': np.random.choice(clases),
                    'edad_paciente': np.random.randint(18, 90),
                    'opacidad_media': np.random.random(),
                    'contraste_medio': np.random.random(),
                    'densidad_pulmonar': np.random.random()
                })
            return pd.DataFrame(datos)
        
        # Usar analizador completo
        return analizador_eda.generar_dataset_simulado(tama√±o_muestra)
    
    def mostrar_resumen_ejecutivo(self, dataset: pd.DataFrame):
        """Muestra resumen ejecutivo del dataset"""
        st.subheader(t("eda.resumen_ejecutivo"))
        
        if MODULOS_DISPONIBLES:
            resumen = analizador_eda._generar_resumen_ejecutivo(dataset)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    label=t("eda.total_radiografias"),
                    value=f"{len(dataset):,}",
                    delta=t("eda.dataset_completo")
                )
                
                # Distribuci√≥n de clases
                distribucion = dataset['clase_diagnostico'].value_counts()
                clase_dominante = distribucion.index[0]
                porcentaje_dominante = (distribucion.iloc[0] / len(dataset)) * 100
                
                st.metric(
                    label=t("eda.clase_dominante"),
                    value=clase_dominante,
                    delta=f"{porcentaje_dominante:.1f}% {t('eda.del_total')}"
                )
            
            with col2:
                # Calidad de datos
                valores_completos = dataset.notna().all(axis=1).sum()
                porcentaje_completo = (valores_completos / len(dataset)) * 100
                
                st.metric(
                    label=t("eda.completitud_datos"),
                    value=f"{porcentaje_completo:.1f}%",
                    delta=t("eda.sin_valores_faltantes") if porcentaje_completo == 100 else f"{100-porcentaje_completo:.1f}% incompleto"
                )
                
                # Edad promedio
                if 'edad_paciente' in dataset.columns:
                    edad_promedio = dataset['edad_paciente'].mean()
                    st.metric(
                        label=t("eda.edad_promedio"),
                        value=f"{edad_promedio:.1f} {t('eda.a√±os')}",
                        delta=f"{t('eda.rango')}: {dataset['edad_paciente'].min()}-{dataset['edad_paciente'].max()}"
                    )
        else:
            st.info("üìä Dataset b√°sico cargado - funcionalidad limitada sin m√≥dulos completos")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total Im√°genes", len(dataset))
            with col2:
                st.metric("Clases", dataset['clase_diagnostico'].nunique())
            with col3:
                st.metric("Variables", len(dataset.columns))
    
    def mostrar_distribucion_clases(self, dataset: pd.DataFrame):
        """Muestra distribuci√≥n de clases diagn√≥sticas"""
        st.subheader(t("eda.distribucion_clases"))
        
        # Calcular distribuci√≥n
        distribucion = dataset['clase_diagnostico'].value_counts()
        porcentajes = (distribucion / len(dataset) * 100).round(1)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Gr√°fico de pastel
            fig_pie = px.pie(
                values=distribucion.values,
                names=distribucion.index,
                title=t("eda.distribucion_clases"),
                color_discrete_map={
                    'COVID-19': '#FF6B6B',
                    'Normal': '#4ECDC4',
                    'Opacidad Pulmonar': '#45B7D1',
                    'Neumon√≠a Viral': '#FFA726'
                }
            )
            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
            fig_pie.update_layout(height=400)
            st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            # Tabla de resumen
            st.markdown(f"### {t('eda.estadisticas_clase')}")
            tabla_resumen = pd.DataFrame({
                'Clase': distribucion.index,
                'Cantidad': distribucion.values,
                'Porcentaje': [f"{p}%" for p in porcentajes]
            })
            st.dataframe(tabla_resumen, use_container_width=True)
            
            # Estad√≠sticas adicionales
            st.markdown(f"### {t('eda.metricas_clave')}")
            st.metric(t("eda.clase_mas_comun"), distribucion.index[0])
            st.metric(t("eda.clase_menos_comun"), distribucion.index[-1])
            
            # Balance del dataset
            balance = (distribucion.max() - distribucion.min()) / distribucion.max() * 100
            balance_label = t("eda.bien_balanceado") if balance < 50 else t("eda.desbalanceado")
            st.metric(t("eda.balance"), f"{balance:.1f}%", balance_label)
    
    def mostrar_estadisticos_descriptivos(self, dataset: pd.DataFrame):
        """Muestra estad√≠sticos descriptivos del dataset"""
        st.subheader(t("eda.estadisticos_descriptivos"))
        
        # Seleccionar variables num√©ricas
        variables_numericas = dataset.select_dtypes(include=[np.number]).columns.tolist()
        
        if not variables_numericas:
            st.warning("‚ö†Ô∏è No se encontraron variables num√©ricas para analizar")
            return
        
        # Mostrar descripci√≥n general
        st.markdown(f"### {t('eda.estadisticos_generales')}")
        descripcion = dataset[variables_numericas].describe()
        st.dataframe(descripcion.round(3), use_container_width=True)
        
        # Estad√≠sticos por clase
        st.markdown(f"### {t('eda.estadisticos_por_clase')}")
        
        if 'clase_diagnostico' in dataset.columns:
            # Crear tabs para cada variable
            variables_interes = ['opacidad_media', 'contraste_medio', 'densidad_pulmonar', 'edad_paciente']
            variables_disponibles = [var for var in variables_interes if var in dataset.columns]
            
            if variables_disponibles:
                tabs = st.tabs([self._traducir_variable(var) for var in variables_disponibles])
                
                for i, variable in enumerate(variables_disponibles):
                    with tabs[i]:
                        # Estad√≠sticos por clase para esta variable
                        stats_por_clase = dataset.groupby('clase_diagnostico')[variable].agg([
                            'count', 'mean', 'std', 'min', 'max'
                        ]).round(3)
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.dataframe(stats_por_clase, use_container_width=True)
                        
                        with col2:
                            # Visualizaci√≥n r√°pida
                            fig_box = px.box(
                                dataset, 
                                x='clase_diagnostico', 
                                y=variable,
                                title=f"{t('eda.distribucion_caracteristicas')} - {self._traducir_variable(variable)}",
                                color='clase_diagnostico',
                                color_discrete_map={
                                    'COVID-19': '#FF6B6B',
                                    'Normal': '#4ECDC4',
                                    'Opacidad Pulmonar': '#45B7D1',
                                    'Neumon√≠a Viral': '#FFA726'
                                }
                            )
                            fig_box.update_layout(height=300, showlegend=False)
                            st.plotly_chart(fig_box, use_container_width=True)
        
        # Informaci√≥n adicional de calidad de datos
        st.markdown(f"### {t('eda.calidad_datos')}")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            valores_faltantes = dataset.isnull().sum().sum()
            st.metric(
                t("eda.valores_faltantes"),
                valores_faltantes,
                f"{(valores_faltantes/dataset.size)*100:.2f}% del total"
            )
        
        with col2:
            duplicados = dataset.duplicated().sum()
            st.metric(
                t("eda.filas_duplicadas"),
                duplicados,
                f"{(duplicados/len(dataset))*100:.2f}% del total"
            )
        
        with col3:
            tipos_datos = dataset.dtypes.value_counts()
            st.metric(
                t("eda.tipos_datos"),
                len(tipos_datos),
                f"{tipos_datos.index[0]} {t('eda.dominante')}"
            )
    
    def mostrar_mapa_calor_correlaciones(self, dataset: pd.DataFrame):
        """Muestra mapa de calor de correlaciones"""
        st.subheader(t("eda.mapa_calor"))
        
        # Seleccionar variables num√©ricas relevantes
        variables_interes = [
            'opacidad_media', 'contraste_medio', 'textura_rugosidad',
            'densidad_pulmonar', 'edad_paciente'
        ]
        
        # Filtrar variables disponibles
        variables_disponibles = [var for var in variables_interes if var in dataset.columns]
        
        if len(variables_disponibles) < 2:
            st.warning("‚ö†Ô∏è Se necesitan al menos 2 variables num√©ricas para calcular correlaciones")
            return
        
        # Calcular matriz de correlaciones
        matriz_correlacion = dataset[variables_disponibles].corr()
        
        if MODULOS_DISPONIBLES:
            # Usar visualizaci√≥n avanzada
            fig = analizador_eda.crear_mapa_calor_correlaciones(dataset)
            st.plotly_chart(fig, use_container_width=True)
        else:
            # Visualizaci√≥n b√°sica con plotly express
            fig = px.imshow(
                matriz_correlacion,
                text_auto=True,
                aspect="auto",
                title=t("eda.mapa_calor"),
                color_continuous_scale='RdBu_r',
                zmin=-1, zmax=1
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
        
        # Mostrar correlaciones m√°s fuertes
        st.markdown(f"### {t('eda.correlaciones_significativas')}")
        
        # Extraer correlaciones (excluyendo diagonal)
        mask = np.triu(np.ones_like(matriz_correlacion, dtype=bool))
        correlaciones_flat = matriz_correlacion.mask(mask).stack().reset_index()
        correlaciones_flat.columns = ['Variable 1', 'Variable 2', 'Correlaci√≥n']
        correlaciones_flat = correlaciones_flat.sort_values('Correlaci√≥n', key=abs, ascending=False)
        
        # Mostrar top 5 correlaciones
        top_correlaciones = correlaciones_flat.head(5)
        top_correlaciones['Variable 1'] = top_correlaciones['Variable 1'].apply(self._traducir_variable)
        top_correlaciones['Variable 2'] = top_correlaciones['Variable 2'].apply(self._traducir_variable)
        top_correlaciones['Correlaci√≥n'] = top_correlaciones['Correlaci√≥n'].round(3)
        
        st.dataframe(top_correlaciones, use_container_width=True)
        
        # Interpretaci√≥n autom√°tica
        if not top_correlaciones.empty:
            correlacion_maxima = top_correlaciones.iloc[0]
            interpretacion = self._interpretar_correlacion(correlacion_maxima['Correlaci√≥n'])
            
            st.info(f"""
            üéØ **Correlaci√≥n m√°s fuerte**: {correlacion_maxima['Variable 1']} ‚Üî {correlacion_maxima['Variable 2']}
            
            üìä **Valor**: {correlacion_maxima['Correlaci√≥n']:.3f} ({interpretacion})
            """)
    
    def mostrar_visualizaciones_avanzadas(self, dataset: pd.DataFrame):
        """Muestra visualizaciones avanzadas del dataset"""
        st.subheader(t("eda.visualizaciones_avanzadas"))
        
        if not MODULOS_DISPONIBLES:
            st.warning("‚ö†Ô∏è Visualizaciones avanzadas requieren m√≥dulos completos")
            return
        
        # Crear tabs para diferentes tipos de visualizaci√≥n
        tab1, tab2, tab3 = st.tabs([t("eda.histogramas"), t("eda.box_plots"), t("eda.scatter_plots")])
        
        with tab1:
            st.markdown(f"### {t('eda.distribucion_caracteristicas')}")
            fig_hist = analizador_eda.crear_histogramas_caracteristicas(dataset)
            st.plotly_chart(fig_hist, use_container_width=True)
            
            st.info("üí° Los histogramas muestran c√≥mo se distribuyen las caracter√≠sticas de imagen en cada clase diagn√≥stica")
        
        with tab2:
            st.markdown(f"### {t('eda.analisis_distribucion')}")
            fig_box = analizador_eda.crear_boxplots_comparativos(dataset)
            st.plotly_chart(fig_box, use_container_width=True)
            
            st.info("üí° Los box plots permiten identificar outliers y comparar la variabilidad entre clases")
        
        with tab3:
            st.markdown(f"### {t('eda.analisis_multivariable')}")
            fig_scatter = analizador_eda.crear_scatter_plot_multivariable(dataset)
            st.plotly_chart(fig_scatter, use_container_width=True)
            
            st.info("üí° El scatter plot muestra relaciones entre m√∫ltiples variables simult√°neamente")
    
    def mostrar_insights_automaticos(self, dataset: pd.DataFrame):
        """Genera y muestra insights autom√°ticos del dataset"""
        st.subheader(t("eda.insights_automaticos"))
        
        insights = []
        
        # Insight 1: Balance de clases
        distribucion = dataset['clase_diagnostico'].value_counts()
        balance_ratio = distribucion.min() / distribucion.max()
        
        if balance_ratio > 0.7:
            insights.append("‚úÖ **Dataset bien balanceado**: Las clases tienen representaci√≥n similar")
        elif balance_ratio > 0.3:
            insights.append("‚ö†Ô∏è **Dataset moderadamente desbalanceado**: Considerar t√©cnicas de balanceo")
        else:
            insights.append("üö® **Dataset muy desbalanceado**: Requiere estrategias especiales de entrenamiento")
        
        # Insight 2: Correlaciones significativas
        if len(dataset.select_dtypes(include=[np.number]).columns) > 1:
            variables_numericas = dataset.select_dtypes(include=[np.number]).columns
            correlaciones = dataset[variables_numericas].corr()
            
            # Encontrar correlaciones fuertes (excluyendo diagonal)
            mask = np.triu(np.ones_like(correlaciones, dtype=bool))
            correlaciones_altas = correlaciones.mask(mask).abs() > 0.7
            
            if correlaciones_altas.any().any():
                insights.append("üîó **Correlaciones fuertes detectadas**: Algunas variables est√°n altamente correlacionadas")
            else:
                insights.append("üìä **Variables independientes**: No se detectaron correlaciones muy fuertes")
        
        # Insight 3: Edad y diagn√≥stico
        if 'edad_paciente' in dataset.columns:
            edad_covid = dataset[dataset['clase_diagnostico'] == 'COVID-19']['edad_paciente'].mean()
            edad_normal = dataset[dataset['clase_diagnostico'] == 'Normal']['edad_paciente'].mean()
            
            if abs(edad_covid - edad_normal) > 10:
                insights.append(f"üë• **Diferencia etaria significativa**: COVID-19 promedio {edad_covid:.1f} a√±os vs Normal {edad_normal:.1f} a√±os")
        
        # Insight 4: Calidad de datos
        valores_faltantes_pct = (dataset.isnull().sum().sum() / dataset.size) * 100
        if valores_faltantes_pct == 0:
            insights.append("‚ú® **Datos perfectos**: Sin valores faltantes en el dataset")
        elif valores_faltantes_pct < 5:
            insights.append(f"‚úÖ **Buena calidad**: Solo {valores_faltantes_pct:.1f}% de valores faltantes")
        else:
            insights.append(f"‚ö†Ô∏è **Atenci√≥n requerida**: {valores_faltantes_pct:.1f}% de valores faltantes")
        
        # Mostrar insights
        for i, insight in enumerate(insights, 1):
            st.markdown(f"**{i}.** {insight}")
        
        # Recomendaciones
        st.markdown(f"### {t('eda.recomendaciones_modelado')}")
        
        recomendaciones = [
            "üéØ Considerar validaci√≥n cruzada estratificada debido a m√∫ltiples clases",
            "üìä Evaluar feature engineering basado en las correlaciones encontradas",
            "üîÑ Implementar data augmentation si el dataset es limitado",
            "üìà Usar m√©tricas balanceadas (F1-score, AUC) para evaluaci√≥n"
        ]
        
        for recomendacion in recomendaciones:
            st.markdown(f"- {recomendacion}")
    
    def generar_reporte_eda_pdf(self, dataset: pd.DataFrame):
        """Genera y descarga reporte PDF para EDA"""
        if not REPORTES_DISPONIBLES:
            st.error("‚ùå Generador de reportes no disponible")
            return
        
        try:
            with st.spinner(t("reportes.generando_reporte")):
                # Crear visualizaciones para el reporte
                visualizaciones = {}
                
                if MODULOS_DISPONIBLES:
                    visualizaciones = {
                        'mapa_calor': analizador_eda.crear_mapa_calor_correlaciones(dataset),
                        'histogramas': analizador_eda.crear_histogramas_caracteristicas(dataset),
                        'boxplots': analizador_eda.crear_boxplots_comparativos(dataset),
                        'scatter': analizador_eda.crear_scatter_plot_multivariable(dataset)
                    }
                
                # Generar PDF
                pdf_content = generador_reportes.generar_reporte_eda(dataset, visualizaciones)
                
                # Crear nombre de archivo localizado
                nombre_archivo = generador_reportes.crear_nombre_archivo('eda', 'pdf')
                
                # Bot√≥n de descarga
                st.download_button(
                    label=t("reportes.descargar_pdf"),
                    data=pdf_content,
                    file_name=nombre_archivo,
                    mime="application/pdf",
                    help=f"Descargar reporte EDA en formato PDF ({nombre_archivo})"
                )
                
                st.success(t("reportes.reporte_generado"))
                
        except Exception as e:
            st.error(f"{t('reportes.error_generacion')}: {str(e)}")
    
    def _traducir_variable(self, variable: str) -> str:
        """Traduce nombres de variables a espa√±ol legible"""
        traduccion = {
            'opacidad_media': 'Opacidad Media',
            'contraste_medio': 'Contraste Medio',
            'textura_rugosidad': 'Rugosidad de Textura',
            'densidad_pulmonar': 'Densidad Pulmonar',
            'edad_paciente': 'Edad del Paciente',
            'entropia_imagen': 'Entrop√≠a',
            'energia_imagen': 'Energ√≠a',
            'homogeneidad': 'Homogeneidad'
        }
        return traduccion.get(variable, variable.replace('_', ' ').title())
    
    def _interpretar_correlacion(self, valor: float) -> str:
        """Interpreta el valor de correlaci√≥n"""
        abs_valor = abs(valor)
        if abs_valor >= 0.8:
            return "Muy fuerte"
        elif abs_valor >= 0.6:
            return "Fuerte"
        elif abs_valor >= 0.4:
            return "Moderada"
        elif abs_valor >= 0.2:
            return "D√©bil"
        else:
            return "Muy d√©bil"
    
    def ejecutar_dashboard_completo(self):
        """Ejecuta el dashboard EDA completo"""
        st.title(t("eda.titulo"))
        st.markdown("---")
        
        # Configuraci√≥n del dataset
        with st.sidebar:
            st.header(t("eda.configuracion"))
            tama√±o_muestra = st.slider(
                t("eda.tama√±o_dataset"),
                min_value=100,
                max_value=2000,
                value=1000,
                step=100,
                help="N√∫mero de radiograf√≠as para el an√°lisis"
            )
            
            regenerar = st.button(t("eda.regenerar_dataset"), help="Generar nuevo dataset para an√°lisis")
        
        # Cargar dataset
        if regenerar or 'dataset_eda' not in st.session_state:
            with st.spinner("üîÑ Generando dataset para an√°lisis..."):
                st.session_state.dataset_eda = self.cargar_dataset_covid(tama√±o_muestra)
            st.success(t("eda.dataset_generado"))
        
        dataset = st.session_state.dataset_eda
        
        # Secciones del dashboard
        self.mostrar_resumen_ejecutivo(dataset)
        st.markdown("---")
        
        self.mostrar_distribucion_clases(dataset)
        st.markdown("---")
        
        self.mostrar_estadisticos_descriptivos(dataset)
        st.markdown("---")
        
        self.mostrar_mapa_calor_correlaciones(dataset)
        st.markdown("---")
        
        self.mostrar_visualizaciones_avanzadas(dataset)
        st.markdown("---")
        
        self.mostrar_insights_automaticos(dataset)
        
        # Secci√≥n de reporte PDF
        st.markdown("---")
        st.subheader("üìÑ Reporte PDF del An√°lisis EDA")
        
        col_pdf1, col_pdf2 = st.columns(2)
        
        with col_pdf1:
            if st.button("üìÑ Generar Reporte EDA PDF", type="secondary", use_container_width=True):
                self.generar_reporte_eda_pdf(dataset)
        
        with col_pdf2:
            st.info("üí° El reporte incluye estad√≠sticas completas, visualizaciones y insights autom√°ticos del an√°lisis exploratorio")
        
        # Footer
        st.markdown("---")
        st.info(t("eda.nota_requisitos"))

# Instancia global del dashboard
dashboard_eda = DashboardEDA()